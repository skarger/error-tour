
Hi everyone, I'm Stephen Karger. Thank you for attending.

So as a heads up this material will range about 45 minutes,
so there will be a little time at the end if people want to stick around for questions or comments.

So let's get into it.

OK, before I get into the specific topic this talk is all about
I want start out with a bigger question.

NS
When it comes to software, what is quality?

What does it actually mean for software to be high quality?

So I thought about this myself, and here's my answer.
Quality software has the following traits:

Build Out 1

* First, does the software provide a nice user interface?
    Does it look good, is it intuitive, does it make it easy to do what you need to do?
* Another trait is performance. If it's responsive and fast then it's higher quality.
* Next, does the software do things correctly?
    This one is context dependent, like say you build a weather forecasting program and you
    use floating point numbers, you will have rounding errors but it can still be
    reasonably correct by the expectations of the program. Vs. if you build
    a payments app with floating point then it will be incorrect in a way that matters.
    A hallmark of good quality software is that it's gone to the trouble of
    sorting out appropriate definitions of correctness for its situation.
* And a final quality trait, does the software handle errors gracefully?
    Our programs encounter errors for different reasons.
    They may be external like network failures, or unexpected user input,
    and also internal bugs like trying to use a null value that you expect to be non-null,
    or calling a library function that throws an exception.
    But when errors happen, the software can still handle it well,
    and that makes a huge difference in the user's experience.

Build Out 2
One reason I like this definition is that it helps distinguish
the meaning of quality from the software's features.
Surely there is some overlap, like sometimes you'll hear people say that performance is a feature,
and I truly understand that point,
but it's different from what we usually understand as domain features.

Also, this helps shed light on why software quality is challenging to attain,
because it is domain features that our business stakeholders request from us.
Features are the front line of making sales, and we have a lot of people around the
business putting coordinated effort into defining the feature roadmap and executing it.
Quality is more of an informal requirement that's up to us in engineering to figure out.

And this talk itself is a small example of trying to level-up on quality.
It's going to do a deep dive on that final quality trait, of error handling.

Handling errors in software is hardly a new topic.
It's more like an ordinary day-to-day issue.
But it's also a deceptive topic, because despite its ordinariness it's not truly solved in practice.
The basic tools for handling errors are readily available,
you can find a section on how to do it in the docs for any programming language.
But they don't provide a clear overall solution for a real software system.
<pause>
When I think of my own experience, across a few different companies,
I'd say the default is to not really have a design for handling errors.
The common approach is to deal with it case-by-case, in a somewhat haphazard way.
You'll hear vague best practices floating around but there's no standard technique.

But I think it's practically the definition of a low-hanging fruit,
where being slightly more deliberate with error handling
is a direct way to produce higher quality software.

And that's the origin of this talk. Earlier this year I was working on a Jira ticket
and during development I realized there were some errors that would happen in production.
They would happen a small percentage of the time, but they definitely would happen,
and that would result in a pretty broken user experience.

So I was writing some code to deal with that, but it felt like it should be more of a solved problem.
I shouldn't be spending time writing this ad-hoc code,
but I didn't have a good alternative in the scope of my ticket.

So I wanted a stronger ethos for how to handle errors, and that led to the questions I'll answer in this talk:

* First, what are the actual goals when it comes to handling errors?
* Then what tools do we have available and what are their tradeoffs?
* And what is an overall error handling strategy that strives to keep things simple but manages to deliver a quality user experience?

NS
OK then. We're looking at the Enhanced Content builder UI in Salsify.
Unluckily for Enhanced Content I'm going to use it for my examples throughout this presentation.
I've opened this publish dropdown in the top-right and it's working as intended,
showing me a collection of retailers where I can send my Enhanced Content.

NS
But in the next slide, this is a real bug that we had.
I click the Publish dropdown, and I just see this empty box.

By the way this bug was never reported to our dev team.
I only found it because I'd noticed it in Bugsnag a few times and investigated.

Well if I open the developer tools I can see that the API request
to load the retailers returned a 503, and that's why it couldn't populate the list.

But imagine the end-user's experience here. They see this empty box.
It's confusing, it's not truly evident that an error occurred.
A user might think they missed some setup step, or maybe
they just don't understand how the app works.

NS
Another example on this next slide, I've just used that sidebar on the right to
update my Enhanced Content layout to reference an Image property.

If I open dev tools though I can see that when I set that value,
the client tried to save the layout, but the API returned a 500.
So even though the UI looks fine, if I reloaded the page
I'd discover that it didn't save my work.

NS
Next I'm going to play a video where I'm looking at my list of Enhanced Content layouts.
Then you'll see I'm going click one of the layout rows and then click the button to copy it.
But under the hood, the API request to copy that layout is going to fail. You'll see that below in my network tab.

Let's watch...

So click, copy, nothing happens, no feedback.

And I want to emphasize that for end users the experience of errors is very frequently like this.
The software behaves in a way that seems off, but it's hard to explain.
It just feels sort of frustrating and unreliable.

NS
All right then so what error experience would we want?
Build out 1
Well first we don't want them to happen in the first place!
Clearly, preventing errors is preferable to dealing with them at runtime.

And we already employ several techniques for that.
Build out 2
Testing, type checking, and code review are all helpful for preventing errors.

NS
But even with all this our software still has errors in production.

Over time we learn about bugs and we fix them,
say by supporting a case we hadn't known about before,
or telling the user to correct their input,
or adding a condition before we execute some logic.

Build out
And this process of widening the range of states that the program can handle,
so that errors become non-errors,
is one of our day-to-day tasks in software maintenance.

But I want to point out that these techniques are before-the-fact and after-the-fact.
When we write tests that guard against an error condition,
by definition it's an error we have thought about,
and we're preventing it ahead of time.
And when we react to errors in production by updating the code so they won't happen again,
we're similarly using knowledge that we already have.

But there's also the set of errors that we don't know about concretely.
Our application has some code path where an error can happen,
but we're not clearly aware that it's a problem yet.

A guiding idea here is that the design needs to confront uncertainty.
When we think about how to handle runtime errors, we're designing for situations
that we don't have complete knowledge about.

In the remainder of this talk we're going to be deeper in the weeds, looking at code,
but keep this main idea in mind:

That error handling concerns situations that are at least partially unanticipated.
<pause>

NS
Therefore the first design principle is communicating to humans.
We cannot implement a fully automated reaction to an unexpected problem.

A good design primarily needs to provide guidance for, how do we inform end users that something went wrong?
But also: how do we inform customer support, PMs, and ourselves?


NS
Now I want to talk about history.

The C language emerged in 1972 and influenced many details of modern software development.

NS
In C error handling conventionally happened via return values.

In this example C program we're making a system call to open a file.

Build Out 1
Opening the file returns a file pointer, and then we're trying to write to the open file.

Build Out 2
But the file doesn't exist. Writing to that non-existent file results in a segfault
and the program is killed by the operating system.

NS
So in the next slide I've fixed that bug.

Build Out 1
Now I have logic to only write to the file if the returned file pointer is not NULL.

Build Out 2
The program continues without crashing.

This works. But there are two problems. First, it's mashing the error signaling into the return value.
The function is supposed to return a file pointer but it might
give us something we cannot use as a file pointer.
Second and more importantly, in C nothing forces you check that return value.
Your program can keep barreling on.
And failing to check return values for errors is a very common cause of bugs,
and those bugs can be confusing, because they may manifest somewhere far downstream
of the original problem and cause the program to suddenly crash,
or write corrupt data, or have a security vulnerability.

NS
So then there was a stretch in the 80s and 90s where some new languages came out that
have become mainstream in commercial software development.
These languages shown here all brought a concept of Exceptions.

NS
I'm going to take a minute to review the basics,
starting with this example in Java.
In this program I want to parse some strings into integers.
It works for the string 1000 but then throws an exception for the string A grand.
And this is the general form of Exceptions:
Try running some code step by step, but if any of the statements fail,
immediately jump to the catch block and execute that code instead.
And then regardless of what happened, execute the code in the finally block.

NS
Next we have a JavaScript example. An interesting point here, unlike Java,
JavaScript's parseInt function does not throw an exception when it fails.
Instead it returns the value NaN, so it's signalling the error with a return value, like C.
But JavaScript still supports the same try-catch-finally construct where it uses Exceptions to signal errors.
For the sake of the example I check for NaN and then explicitly throw an exception.

NS
And then here is an example in Ruby, same exact concept, just using the words begin rescue ensure
instead of try catch finally.
<pause>

So Exceptions were a way of preventing the problem in C where the programmer forgets to check return values.
Because exceptions forcibly re-route the code execution.

NS
But even though that's helpful it creates some other problems.
Exceptions introduce implicit control flow, sort of like a GOTO statement.

Here we have function a who calls b who calls c,
and c raises an exception.
And the handler block that catches it lives in some other file.

The presence of Exceptions can make the logic hard to reason about,
because as you trace the code it's no longer totally linear.
If any function call raises an exception then it can abruptly yank the execution to some code far away.

A closely related problem is that since exceptions will eject up through the call stack,
you can have functions at intermediate levels that put the program into an inconsistent state.

Looking at this code on the slide, imagine that it lives in a Salsify service.
And in function b the goal is compute a new value for a product,
and then save some bookkeeping data about that to the service's database.

Then b calls function c to make a request to dandelion to update the product,
but that raises an exception, and the product isn't actually updated.
So we shoot right to the handler block in the lower code snippet,
and b never has the chance to undo the DB update,
so our program ends up in an inconsistent state.

NS
And a couple more recent languages that have become popular
said about that exceptions thing, maybe that wasn't the right idea after all.

Build Out
In Go and Rust the primary way to signal errors is with return values, like C, just with some twists.

NS
In Go, the big change compared to C is that functions return two distinct values,
with the error value in the second position,
so return values and errors are not overloaded.
(pause)
And this gets rid of the control flow jumps. But you are free to ignore the error value again.

NS
In Rust, they moved the problem into the type system.
(pause)
The standard approach for functions that can fail is to wrap the return value in a Result type.
A Result data type has two variants, Ok or Err,
and the Rust type checker forces you to cover those possibilities.
So Rust doesn't have Exceptions, but the compiler prevents you from forgetting to handle errors.

This style of wrapping a return value in Result type supports a functional style of programming,
because instead of throwing an exception as this side effect of your function call,
you're just passing data in and getting data out.

NS
I'll show a more involved example of that next.
On this first slide I've written these three helper functions.
First the parse_number function tries to convert a string to an integer and returns a Result type,
where the Err value is a ParseIntError,
ensure_positive checks if an integer is greater than 0 and returns a Result type,
where the Err value is a String,
and double just multiplies a number by 2 and returns a plain number.
<pause>

NS
So then in the next slide I have a full demo using these functions.
The main program passes different strings to this function that I've named two_track_computation.

Rust provides a lot of tools to work with these Result types.
Looking at two_track_computation, it starts out by calling parse_number,
and the Result value flows into map_err which is just there
to adjust the type of Err value from a ParseIntError to a string,
and then it flows into the ensure_positive function, then it tries to
double the result, and finally it produces a string value depending on
whether the Result was Ok or Err.

The details of Rust aren't important here, the point is to see the pattern.
The data is flowing in a linear way from function to function,
with errors at any point conveyed inside these values of data type Result.
There are no Exceptions that cause the control flow to jump. Data-in, Data-out.

NS
This style is not unique to Rust,
in 2014 an F# programmer named Scott Wlaschin
wrote a blog post naming this style Railway Oriented Programming.
It's where data flows through your program
like it's on a railroad track, and as long as it's successful it keeps rolling along that success track,
but if it encounters an error at any point it switches to the error track.


NS
And you can string together a functional pipeline this way.
So this can be easier to follow than the control flow jumps you get with exceptions.

Now we can adopt a Railway Oriented style in Ruby and JavaScript,
where we represent errors as data that we return from functions.
And then for example using TypeScript you can even enforce
that the code handles the success and error variants,
which you may have seen in our graphql client library.

NS
But there are some tradeoffs to consider about that.

When I say errors-as-data I'm lumping together all these styles of signaling errors with return values,
whether it's a Result type like in Rust, or a C-style error code,
or any other returned data indicating that an error happened.

The key contrast is that Exceptions forcibly unwind the call stack,
and errors-as-data do not.

One place where representing errors as data fits well is for errors that are part of the program's domain.
If encountering this error is a normal event that you expect to happen sometimes,
then it's nice to process that error as plain old data flowing through the program,
rather than using a special exception handling construct.

That's really a way of re-stating what I mentioned earlier that a core issue when
handling errors is dealing with situations we do not expect. But now I'll make that more
precise by saying that it's actually Exceptions that fit best with unexpected situations.
When something happens that really is outside the circumstances this program is intended to support,
exceptions are a helpful way to just bail out immediately.

However I want to note that it can be fuzzy to decide
whether something is a normal expected problem or if it's exceptional.

An example of that which comes up at Salsify is when we make HTTP requests
between our backend services. Now it's well within the domain of HTTP itself
that you can receive a 404 or a 500 response.
But when we're making inter-service requests,
getting those response statuses is usually not part of our application's domain. It's not quite like web browsing.
The HTTP request is just an implementation detail of our service architecture,
it happens to be how we're loading data.
If we don't get a 200-level response it most likely means something has gone wrong
in a way that we aren't intending to support as a normal case in our domain.
We can retry if it's a transient network error,
but otherwise the application just has to bail out.
So raising an exception when a backend service sees that 404 response is a sane default.

NS
Then another tradeoff to consider with errors-as-data is loose coupling.
Thinking again of a web API, when it needs to return an error, how do we do it?
We're obligated to put the error on the wire.
We need to transmit it to a different computer running a different program.
So we send the error as data, maybe an HTTP response with status code 500,
and maybe we send a JSON payload with an errors field.

When we have two programs communicating remotely,
there's this imperative to make them work with looser coupling.

But even inside one program it may be useful to apply that lesson from web APIs,
and pass pure data around to promote modularity.
If we want to have a clear boundary in our program, we can ask:
Will this work if between these two sub-systems I only can pass data?
If I were to extract these two parts into separate programs,
would it work to communicate over a web API or a message queue?
And could they effectively signal errors to each other?

If it's desirable for those parts of the program to be loosely coupled,
then one of the steps toward that is to communicate errors as data.

NS
Another practical tradeoff between exceptions and errors-as-data is
Are you working in a platform that has exceptions?

Build Out
So Clojure is a language designed to run on the JVM and have seamless interop with Java.

And with TypeScript, yes we can use the type-checker to support static enforcement of Result types
in a similar style to Rust, but TypeScript is meant to integrate directly into JavaScript.

NS
You can see in this Clojure example it's calling Java to try to parse the string to an integer,
it calls the Java parseInt function to do that,
which throws the exact same Java exception as in the earlier example.

So even though Clojure is functional language that puts heavy emphasis on passing data
through your program, as a practical matter Java throws exceptions so Clojure has to work with that.

And similarly with TypeScript we still need to deal with JavaScript exceptions.
So unless it's truly helpful to process the error as data,
if you want to bail out then might as well just throw an exception.

NS
A final important consideration is how do we make errors visible to ourselves?

A key challenge for developers is that errors are hard to see.
They happen infrequently, and they often only come out in real-world usage, and they're underreported.
So mentally it's easy discount their importance.

Sometimes we realize there's a potential for an error, but we dismiss it as an "edge case".

NS
When we call something an edge case it's like we have this square representing all the cases,
and most are the yellow in the middle there,
but there's a thin edge of cases around the outside that we're not covering.

But you need error reporting to understand the size of the edge.

NS
Is it more like this? And if so we really ought to deal with it.

NS
In one of my previous jobs we had a situation where most of the time our cases looked like this,
but on the two days of the year when the times changed for daylight savings,

NS
the edge was like this and we would have an avalanche of customer problems.
But then things would settle down and we'd kind of forget about fixing it.

In general we need records of errors to understand whether they are a priority.

A pitfall with errors-as-data is that if you don't have any meaningful way to process the error,
then it's easy to end up just silently discarding it.
Vs. when an unhandled exception is thrown we have infrastructure to report it to Bugsnag automatically.
Worth noting though that if the code handles an exception but still want see it in Bugsnag then you need to report it manually.
So if you use data values for errors you can still have Bugsnag
 tracking as long as you make sure to report them manually,
 but just be aware that you won't have a stack trace.


NS
For the back third of this talk I want to get into some more Salsify-specific details.
At the beginning I was talking about doing more deliberate design for error handling,
but the truth is we already do that to some degree in our shared libraries.

NS
Starting out on the backend, here's a snippet from the SalsifyGraphQLServer ruby gem
which I've shortened to show on the slide.
For every GraphQL request, the BaseController will catch exceptions as a last resort.
It uses our ExceptionReporter gem to report them to Bugsnag.
Then it translates the error into an API response following GraphQL conventions for an error payload.

(pause to look at code)

NS
For background jobs, Salsify has an extension to Delayed Job.
It has a similar approach of catching errors and reporting them to Bugsnag, and that happens at the top level where the job
is kicked off.
(pause to look at code)

So if you're using these libraries then you automatically have this error handling framework.
And this is a very helpful default, but by itself it's not enough to attain high quality error handling.

What I've shown so far is backend only. But once we translate the error into an API response payload, then what?
Or in the case of a background job, once we catch the error, then what?

We still need to communicate to the end user.

Making that final step, connecting the dots on the client side, is crucial to a quality experience.
That may be an obvious point but in real world development it's easy for it to fall through the cracks.

NS
That said, just as with the backend libraries, we already do have some built-in default error handling within the main Salsify client app.

What the frontend error handler service provides is when an Ember route tries to load data from the API,
but the API request returns an error status,
the client will flash an error message in a bar near the top of the screen.
It's a bit generic but at least it's providing feedback to the end-user that something went wrong.

But I want to remind you of those examples I showed at the beginning
with the Enhanced Content UI where the end user
gets no indication when the API returns errors.

So, in theory Salsify has this built-in feedback in the UI for failed API requests,
but in practice it's not always working.

In those specific examples there are a couple different reasons why it doesn't work
that come out of low-level details in the Enhanced Content engine.
So you could blame the EC engine for this.
But I hope many of you can understand when we're working on an Ember engine,
we can't see the true behavior for failed requests when we use
a normal development workflow with ember serve, or with our engine's automated test suite,
because that message bar behavior is provided by the main app in dandelion.
The only way to verify it in a realistic way is to package our engine into dandelion
and test end-to-end, including forcing the backend API server to return a 500.

This is a place where the micro-frontends initiative should help, because a micro-app will
be able to manage more of its own UI, including its error display, so we won't have the same pitfalls as with an engine.

Still though, I like the overall idea in the current dandelion client to have a default,
where if an API request fails, let's at least provide some visual feedback.

Because it ultimately doesn't matter whether the server indicates errors in a well-formatted way,
if we don't carry that through end-to-end so that the client communicates the problem to the user.

In these examples I focused on synchronous web requests,
but communication of background job failures is even more important for a lot of Salsify features.

As I showed before we have the backend error reporting extension for DelayedJob,
but we don't automatically have some screen in-app where we would display failed jobs to the user.

So one actionable takeaway here is every time we add a new background job, establish with PM and UX how to communicate to users when it fails.
Similarly, for any new API request the client makes, a good baseline is to verify that failures actually will flash an error message in the style of the main dandelion client.

NS
Beyond server errors, I want to cover errors in the client itself.

NS
In this slide, I have a try-catch block set up that handles when I call this undefinedFunction on line 2.
But see lower down on line 7 there's no catch block where I call anotherUndefinedFunction.

Build Out 2
When a JavaScript runtime error happens but it's not handled by any catch block,
the browser will fire the window.onerror event.

Build Out 3
And that can be configured to run a function as a last resort error handler.

NS
For rejected promises, similar idea but slightly different.

Build Out
Here I have a promise that will reject because it tries to parse HTML as JSON.
But in the code there's no catch chained onto that promise.

NS
In this case the browser will fire the unhandledrejection event.

This can be configured as the last resort handler for rejected promises.

In fact, in a vanilla JavaScript browser application
Bugsnag sets up error reporting by configuring those two events.

NS
In our case, Ember provides a function, Ember.onerror,
that's meant as the backstop for unhandled errors in Ember apps.

Build Out
And then Salsify's error-reporting library sets Ember.onerror.
It configures our reporting to Bugsnag.
Currently there's a one-time setup for that in Dandelion,
and then it applies to all our mounted engines.

But it does mean in your engine you can't override Ember.onerror yourself.
In particular you can't use it as a way to communicate problems to end users, in addition to the Bugsnag reporting.
But it will bubble the errors up to those built-in browser events. I'll come back to that in a couple minutes.

NS
Now let me make this more visual with an example of a client error.
Here we're looking at the list of Enhanced Content layouts again.

Notice the rows of the table. They're Ember components.

Build Out 1
So we have a component representing the table row.
And then we have a couple components nested inside of it

Build Out 2
one that displays what retailers you've published this layout to,
Build Out 3
and another component that shows the status of the layout.

Build Out 4
And lastly I want to point out this other component up at the top that's showing my Amazon quota,
where it says I've used 0 out of my 750 allowed publishes for the month.

OK so imagine that that "Most Recent Status" component throws an exception, what's going to happen?

NS
Well the overall layout table still renders, but because the status component errored, everything
after it is gone. You can see there's no status, but also the rows after the first one aren't showing.

Build Out
Also, a somewhat unpredictable side effect is this Amazon quota bar breaks as well,
where now it's not showing counts anymore.
That happens because the Amazon quota count is asynchronously fetched,
and the error thrown in status component happened before it finished processing.

Now more than anything else, we would want errors like this reported to Bugsnag so we
can address it and prevent it from happening in the future,
and we get that from the error reporting library.

But the experience for end-users is the app just seems busted.
So what would it take to create a higher quality experience?

Again for unexpected errors our strategy devolves to communication.

The first approach that came to my mind was to flash an error message on the same page.
But one question is where you would do that, since you can't use Ember.onerror?

Well you can use those built-in browser events.
At that point you are outside of Ember, so you're on your own,
for example you can't use the Ember flash-message service.
But instead you could inject a standalone DOM node to show an error message,
or maybe even fully redirect to an error page, like a server-rendered website.
It's not that sophisticated but it's a lot better than nothing.

NS
I want to go back to the server-side for a moment and discuss
the tactic that our DelayedJob extension takes, where it handles errors at the edges.
It's at the entrypoint to the program, at the top-level of executing a given background job.
That's a starting point for some business domain action. That makes it a good seam for communicating errors.

If the backend handles all errors at the boundary of the action,
it provides a natural subject to communicate about to the end user.
If it failed, then no matter why it failed,
whatever deep internal code of the application caused the problem,
as a communication strategy we can just reference the top-level domain action that prompted the error.

Like if we're executing a background job that publishes Enhanced Content, then at the entry point to that job
we know that context, so the simple strategy is to handle all errors there, and for the end-user, just say
"This attempt to publish your content failed."

That strategy also works nicely for REST APIs because each URL is an entry point for a domain action.
So the web controller can simply say something like "Failed to copy your Enhanced Content layout," regardless of the lower-level
details that caused the error.

NS
But notice it doesn't quite work that neatly for GraphQL because we don't have server-defined
seams like that, since the single GraphQL endpoint is processing arbitrary queries.

Build Out 1
In this example query,
suppose one of the GraphQL field resolvers raises an exception.

Build Out 2
Thanks to SalsifyGraphQLServer's BaseController, we'll package this into a GraphQL errors response.
It will set the returned message to "Internal server error".

But if we display that message in the client it won't
communicate anything about the specific domain action that prompted the error.
That's extra relevant for SPAs because the client
is often firing off multiple requests,
they don't correspond one-to-one with the user's clicks.

NS
So one way to try to confront that is to view each GraphQL field as an entry point.

Build Out 1
In this version I'm rescuing errors for the field-level resolver and turning it into a user-oriented error message.

Build Out 2
And then the response provides a message that the client could display.
But you can see that adding error handlers at this level would add a ton of extra code.
Plus, the error message we could set for an individual field still
couldn't know how to communicate about the overall request.

So for GraphQL requests I'd want re-frame the understanding of what the entrypoint is, and say it's actually
the client side request. The client will have context on the domain action it's doing when it submits that
GraphQL query, so if the server errors, the client can display a message referencing that domain action.
And then if the client wants to add in the message field returned by the server,
sure, sometimes that may add some helpful details.
But the key design tactic is we've defined the entry point in a way
that supports a reasonable communication to the end user.
The art to that is we have to think of the whole system, we can't just think in terms of one codebase.

OK. So then for errors in the client application we have a similar challenge
because the client has so many entry points.
Every component action and every attribute in every nested component
are independent entry points that can error.

For component actions, those are mostly one-to-one with end-user actions.
Therefore they make good entrypoints to communicate about,
so it would make sense to catch exceptions at their top-level.

For unhandled errors in component attributes, it's a very similar problem to errors resolving GraphQL queries,
where if we tried to catch exceptions at all of them individually it
would add a ton of code but still not provide the right level of detail to communicate.

So again I'd suggest re-defining the entrypoint, and say that it's the whole engine or micro-app.
As mentioned we can use those built-in browser events, to say something like "Enhanced Content system error."
Now I admit that's pretty coarse grained,
but it successfully puts a backstop in place to ensure we have basic communication for any error.

NS
Because the fundamental idea here is that when a runtime exception happens,
to achieve a good quality user experience we need to communicate it,
but moreover, communicating is the only reliable thing we can do.

I see this as a key insight, because historically most programming languages signal errors in a way
that blurs together different kinds of issues, so it's too easy to lose track of this point, that
Either, the program already knows how to deal with this issue as a part of its domain so it can process it as normal data,
or it does not, so its only recourse is to report the issue to humans.

That drives this design of pushing error handling to the boundaries.
Because if we understand exceptions this way, then there's absolutely no point messing around
with error handling in lower-levels of our programs.

But that mindset is different than a lot of real-world code, including what I've written myself,
where error handling logic is strewn throughout the codebase.
Sometimes it catches exceptions at some intermediate level,
but then just logs it and stops, so the overall domain action silently fails.
Or other times it lets an exception raise with a rough idea that someone upstream should handle it,
but the only someone is those backstops we have to report it to Bugsnag. There's no application-level handler.
So we don't add up to a quality experience for end-users.

The solution is to make sure we deal with exceptions adequately at the boundaries.
Because then we can have the confidence to not bother with error handling code at lower levels at all.
Literally, be optimistic, only write code that assumes everything is going to work. Keep it simple.
And when an exception is thrown just handle it at the boundary
by telling the user that it happened, and report it to Bugsnag.

Now this is a talk and therefore I have to oversimplify a little.
The truth is once in awhile we will be calling a function and we know it can throw an exception
but our program has a clear way to recover and keep going.
So sure, it make sense to wrap a handler around that one call.
Honestly situations like that are rare though,
and it's often better to let them emerge in production use than try to pre-emptively handle them.

This handle-at-the-boundary approach is a good mental framework,
because it naturally implies a checklist, where each time we add a business feature,
that's the time to ask, what is the entry point here,
and when it errors how will we communicate to end-users?
Pull that off and you have high quality error handling.

OK that's it, thank you, and I'm happy to take any questions or comments.

