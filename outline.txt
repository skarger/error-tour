Hi everyone, I'm Stephen Karger. Thank you for attending.

So this material will range about 45 minutes,
so there will be a little time at the end if people want to stick around for questions or comments.

So let's get into it.

OK, before I get into the specific topic this talk is all about
I want start out with a bigger question.

NS
When it comes to software, what is quality?

What does it actually mean for software to be high quality?

So I thought about this myself, and here's my answer.
Quality software has the following traits:

Build Out 1

* First, does the software provide a nice user interface?
    Does it look good, is it intuitive, does it make it easy to do what you need to do?
* Another trait is performance. If it's responsive and fast then it's higher quality.
* Next, does the software do things correctly?
    This one is context dependent, like say you build a weather forecasting program and you
    use floating point numbers, you will have rounding errors but it can still be
    reasonably correct by the expectations of the program. Vs. if you build
    a payments app with floating point then it will be incorrect in a way that matters.
    A hallmark of good quality software is that it's gone to the trouble of
    sorting out appropriate definitions of correctness for its situation, and implemented them.
* And a final quality trait, does the software handle errors gracefully?
    Our programs encounter errors for external reasons like network failures, or unexpected user input,
    but also internal bugs like trying to use a null value that you expect to be non-null.
    When errors happen, though, the software may still handle it well,
    and that makes a real difference in the user's experience.

Build Out 2
One reason I like this definition is that it helps distinguish
the meaning of quality from the software's features.
Surely there is some overlap, like sometimes you'll hear people say that performance is a feature,
and I truly understand that point,
but it's different from what we usually understand as domain features.

Also, this helps shed light on why software quality is challenging to attain,
because it is domain features that our business stakeholders request from us.
Features are the front line of making sales, and we have a lot of people around the
business putting coordinated effort into defining the feature roadmap and executing it.
For quality it's more of an informal requirement,
and we rely on various engineering-driven efforts to pull it off.

And this talk itself is a small example of trying to level-up on quality.
It's going to do a deep dive on that final quality trait, of error handling.

Handling errors in software is hardly a new topic,
it's more like an ordinary day-to-day concern in software engineering.
But I also believe that it's a deceptive topic, because despite its ordinariness it's not solved in practice.
<pause>
An ongoing challenges we have in software development is to keep it simple and just solve today's problem.
That's a response to a very common reality where over-engineering leads to complexity and maintainability problems.

Well as an industry we've done an excellent job of not over-engineering when it comes to error handling.
The default approach there is to not really design it at all,
and deal with it case-by-case, likely in an inconsistent and incomplete way.

But I think it's practically the definition of a low-hanging fruit,
where being slightly more deliberate with error handling
is a direct way to produce higher quality software.

And that's the origin of this talk. Earlier this year I was working on a random Jira ticket
and during development I realized there were some potential errors,
so I was writing some ad-hoc code to handle that, and I said I've been here before.
I didn't want to spend time writing custom code,
but the only alternative in the scope of my ticket would have been to leave the code in a state
where these errors would have created a very broken user experience.

So I said, I believe this should be more of a solved problem, but what is the solution?

The aim of this talk is to take on that question, and it will do that by covering a few details:
* First, what are the actual goals when it comes to handling errors?
* Then what tools do we have available and what are their tradeoffs?
* And what is an overall strategy that strives to keep things simple but manages to provide a quality user experience?

NS
OK then. We're looking at the Enhanced Content builder UI in Salsify.
In this presentation I'm going to pick on Enhanced Content a lot.
I've opened this publish dropdown in the top-right and it's working as intended,
showing me a collection of retailers where I can send my Enhanced Content.

NS
But in the next slide, this is a real bug that we had.
I click the Publish dropdown, and I just see this empty box.

By the way this bug was never reported to our dev team.
I only found it because I'd noticed it in Bugsnag a few times and investigated.

Well if I open the developer tools I can see that the API request
to load the retailers returned a 503, and that's why it couldn't populate the list.

But imagine the end-user's experience here. They see this empty box.
It's confusing, it's not truly evident that an error occurred.
A user might think they missed some setup step, or maybe
they just don't understand how the app works.

NS
Another example on this next slide, I've just used that panel on the right-hand side to
update my Enhanced Content layout to reference an Image property.

If I open dev tools though I can see that when I set that value,
the client tried to save the layout, but the API returned a 500.
So even though the UI looks fine, if I reloaded the page
I'd discover that it didn't save my work.

NS
Next I'm going to play a video where I'm looking at my list of Enhanced Content layouts.
Then you'll see I'm going click one of the layout rows and then click the button to copy it.
But under the hood, the API request to load that layout is going to fail. You'll see that below in my network tab.

Let's watch...

So click, copy, nothing happens, no feedback.

And I want to emphasize that for end users the experience of errors is very frequently like this.
The software behaves in a way that seems off, but it's subtle. It's hard to understand cause and effect.
The software just feels sort of frustrating and unreliable,
but it's difficult for users to even explain the problem.

NS
All right then so what error experience would we want?
Build out 1
Well first we don't want them to happen in the first place!
Clearly, preventing errors is preferable to dealing with them at runtime.

And we employ several techniques for that.
Build out 2
Testing, type checking, and code review are all helpful for preventing errors.

NS
But even with all this our software still has errors in production.

Over time we learn about bugs and we fix them,
say by supporting a case we hadn't known about before,
or telling the user to correct their input,
or adding a condition before we try to execute some logic.

Build out
And this process of widening the range of states that the program can handle,
so that errors become non-errors,
is one of our day-to-day tasks in software maintenance.

But I want to point out that these techniques are before-the-fact and after-the-fact.
When we write tests that guard against an error condition,
by definition it's an errors we have thought about,
and we're preventing it ahead of time.
And when we react to errors in production by updating the code so they won't happen again,
we're again using knowledge that we already have.

There's also category of errors that we don't know about concretely.
Our application has some code path where an error can happen,
but we're not clearly aware that it's a problem yet.

A guiding idea here is that the design needs to confront uncertainty.
When we think about how to handle runtime errors, we're designing for situations
that we don't have complete knowledge about at this moment.

In the remainder of this talk we're going to be deeper in the weeds, looking at code,
but keep this main idea in mind:

That error handling concerns situations that are at least partially unanticipated.
<pause>
Therefore the first design principle is communicating to humans.
We cannot implement a fully automated reaction to an unexpected problem.

A good design primarily needs to provide guidance for, how do we inform end users that something went wrong.
    but also:
        how do we inform customer support, and PMs,
        and how do we inform ourselves?

NS
Now I want to talk about history.

The C language emerged in 1972.

NS
In C error handling conventionally happened via return values.

In this example C program we're making a system call to open a file.

Build Out 1
Opening the file returns a file pointer, and then we're trying to write to the open file.

Build Out 2
But the file doesn't exist. Writing to that non-existent file results in a segfault
and the program is killed by the operating system.

NS
So in the next slide I've fixed that bug.

Build Out 1
Now I have logic to only write to the file if the returned file pointer is not NULL.

Build Out 2
The program continues without crashing.

This works. But there are two problems. First, it's mashing the error signaling into the return value.
The function is supposed to return a file pointer but it might
give us something we cannot use as a file pointer.
Second and more importantly, in C nothing forces you check that return value.
Your program can keep barreling on.
And failing to check return values for errors is a very common cause of bugs,
and those bugs can be confusing, because they may manifest somewhere far downstream
of the original problem and cause the program to suddenly crash,
or write corrupt data, or have a security vulnerability.

NS
So then there was a stretch in the 80s and 90s where some new languages came out that
have become mainstream in commercial software development.
These languages shown here all brought a concept of Exceptions.

NS
I'm going to take a minute to review the basics,
starting with this example in Java.
In this example I want to parse some strings into integers.
It works for the string 1000 but then throws an exception for the string A grand.
And this is the general form of Exceptions:
Try running some code step by step, but if any of the statements fail,
immediately jump to the catch block and execute that code instead.
And then regardless of what happened, execute the code in the finally block.

NS
Next we have a JavaScript example. An interesting point here, unlike Java,
JavaScript's parseInt function does not throw an exception when it fails.
Instead it returns the value NaN, so it's signalling the error with a return value, like C.
But JavaScript still supports the same try-catch-finally construct where it uses Exceptions to signal errors.
For the sake of the example I check for NaN and then explicitly throw an exception.

NS
And then here is an example in Ruby, same exact concept, just using the words begin rescue ensure
instead of try catch finally.
<pause>

So Exceptions were a way of preventing the problem in C where the programmer forgets to check return values.
Because exceptions forcibly re-route the code execution.

NS
But even though that's helpful it has a dark side.
Exceptions introduce implicit control flow, sort of like a GOTO statement, where they make code abruptly jump.

Here we have function a who calls b who calls c,
which is a little more like a real program
where we have a deep call stack,
which often will span multiple files.

We won't always have a compact try/catch or begin/rescue
where you can see everything at a glance.
The error handling code may live far away from whatever throws the exception.

This can make the logic hard to reason about,
because as you read the code it's no longer totally linear.
If any function call raises exception then it can yank the execution to some far away handler block.

A closely related problem is that since exceptions will eject up through the call stack,
you can have functions at intermediate levels that put the program into an inconsistent state.

Looking at this code on the slide, imagine that in function b
we compute new values for a Salsify product and we update an in-memory cache with those values.
Then function c is supposed to make a request to dandelion to update the product,
but it raises an exception, and the product isn't actually updated.
So we shoot right to the handler block on line 16,
and b never has the chance to undo the update to the cache,
so our program ends up in an inconsistent state.

That's even more of a concern with lower-level programming where
you are directly managing memory or files or interfacing with hardware.
While researching this talk I found a story about incorporating C++
into the software for driving the Mars rover,
and one of their decisions was to not use exceptions at all, too risky.

NS
And a couple recent languages that have become popular decided not to have exceptions at all.

Build Out
Go and Rust went back to signalling errors with return values, like C, just with some twists.

NS
In Go, the big change compared to C is that functions return two distinct values,
with the error value in the second position,
so return values and errors are not overloaded.
(pause)
And this gets rid of the control flow jumps. But now you are free to ignore the error value again.

NS
In Rust, they moved the problem into the type system.
(pause)
The standard approach for functions that can fail is to wrap the return value in a Result type.
A Result data type has two variants, Ok or Err,
and the Rust type checker forces you to cover those possibilities.
So Rust doesn't have Exceptions, but the compiler prevents you from forgetting to handle errors.

This style of wrapping a return value in Result type supports a functional style of programming,
because instead of throwing an exception as this side effect of your function call,
you're just passing data in and getting data out.

NS
I'll show a more involved example of that next.
On this first slide I've written these three helper functions.
First the parse_number function tries to convert a string to an integer and returns a Result type,
where the Err value is a ParseIntError,
ensure_positive checks if an integer is greater than 0 and returns a Result type,
where the Err value is a String,
and double just multiplies a number by 2 and returns a plain number.
<pause>

NS
So then in the next slide I have a full demo using these functions.
The main program passes different strings to this function that I've named two_track_computation.

Looking at two_track_computation, it starts out by calling parse_number,
and the Result value flows into map_err which is just there
to adjust the type of Err value from a ParseIntError to a string,
and then it flows into the ensure_positive function, then it tries to
double the result, and finally it produces a string value depending on
whether the Result was Ok or Err.

The details of Rust aren't important here, the point is to see the pattern.
The data is flowing in a linear way from function to function,
with errors at any point conveyed inside these values of data type Result.
There are no Exceptions that cause the control flow to jump. Data-in, Data-out.

NS
This style is not unique to Rust,
in 2014 an F# programmer named Scott Wlaschin
wrote a blog post naming this style Railway Oriented Programming.
It's where data flows through your program
like it's on a railroad track, and as long as it's successful it keeps rolling along that success track,
but if it encounters an error at any point it switches to the error track.


NS
And you can string together a functional pipeline this way.
So this can be easier to follow than the control flow jumps you get with exceptions.

Now we can adopt a Railway Oriented style in Ruby and JavaScript,
where we represent errors as data that we return from functions.
And then using TypeScript for example you can even enforce
that the code handles the success and error variants.

NS
But there are some tradeoffs to consider about that. I'll mention a few of them.

When I say errors-as-data I'm lumping together all these styles of signaling errors with return values,
whether it's a Result type like in Rust, or a C-style error code,
or any other returned data indicating that an error occurred.
The key contrast is that Exceptions have that forcible unwinding of the call stack,
and errors-as-data does not.

One place where representing errors-as-data fits well is for errors that are part of the program's domain.
If encountering this error is a normal event that you expect to happen sometimes,
then it's nice to process that error as plain old data flowing through the program,
rather than using a special exception handling construct.

That's really a way of re-stating what I mentioned earlier that a core issue when
handling errors is dealing with situations we do not expect. But now I'll make that more
precise by saying that it's actually Exceptions that fit best with unexpected situations.
When something happens that really is outside the circumstances this program is intended to support,
exceptions are a helpful way to just bail out immediately.

However I want to note that it can be fuzzy to decide
whether something is a normal expected problem or if it's exceptional.

An example of that which comes up at Salsify is when we make HTTP requests
between our backend services. Now it's well within the domain of HTTP itself
that you can receive a 404 or a 500 response.
But when we're making inter-service requests,
getting those response statuses is usually not part of our application's domain,
because the HTTP request is just an implementation detail of our service architecture,
it happens to be how we're loading data.
If we don't get a 200-level response it most likely means something has gone wrong
in a way that we aren't intending to support as a normal case in our domain.
We can retry if the error response is a transient network error,
but otherwise the application just has to bail out at that point.
So raising an exception when a backend service sees that 404 response is a sane default.

NS
Then another tradeoff to consider with errors-as-data is loose coupling.
Thinking again of a web API, when it needs to return an error, how do we do it?
We're obligated to put the error on the wire.
We need to transmit it to a different computer running a different program.
So we send the error as data, maybe an HTTP response with status code 500 or 404,
and maybe we send a JSON payload with an errors field.

When we have two programs communicating remotely,
there's this imperative to make them work with looser coupling.

But even inside one program it may be useful to apply that lesson from web APIs,
and pass pure data around in our program to promote modularity.
If we want to have a clear boundary in our program, we can ask:
Will this work if between these two sub-systems I only can pass data?
If I were to extract these two parts into separate programs,
would it work to communicate over a web API or a message queue?
And could they effectively signal error situations to each other?

If it's desirable for those parts of the program to be loosely coupled,
then one of the steps toward that is to communicate errors as data.

NS
Another practical tradeoff between exceptions and errors-as-data is
Are you working in a platform that has exceptions?

Build Out
So Clojure is a language designed to run on the JVM and have seamless interop with Java.

And with TypeScript, yes we can use the type-checker to support static enforcement of Result types
in a similar style to Rust, but TypeScript is meant to integrate directly into JavaScript.

NS
You can see in this Clojure example it's calling Java to try to parse the string to an integer,
it calls the Java parseInt function to do that,
which it throws the exact same Java exception as in the earlier example.

So even though Clojure is functional language tha puts heavy emphasis on passing data
through your program, as a practical matter Java throws exceptions so Clojure has to work with that.

And similarly with TypeScript we still need to deal with JavaScript exceptions anyway.
So unless it's truly helpful to process the error as data,
then might as well just throw an exception to bail out.

NS
A final important consideration is how do we make errors visible to ourselves?

A key challenge is that errors are hard for developers to see.
They happen infrequently, and they often only come out in real-world usage.
So mentally it's easy discount their importance.

Sometimes we realize there's a potential for an error, but we dismiss it as an "edge case".

NS
When we call something an edge case it's like we have this square representing all the cases,
and most are the yellow in the middle there,
but there's a thin edge of cases around the outside that we're not covering.

But you need error reporting to understand the size of the edge.

NS
Is it more like this? And if so we really ought to deal with it.

NS
In one of my previous jobs we had a situation where most of the time our cases looked like this,
but on the two days of the year when the times changed for daylight savings time,

NS
the edge was like this and we would have an avalanche of customer problems.
But then things would settle down and we'd kind of forget about fixing it.

In general we need records of errors to understand whether they are a priority.

A pitfall with errors-as-data is that if you don't have any meaningful way to process the error,
then it's easy to end up just silently discarding it.
Vs. when an unhandled exception is thrown we have infrastructure to report it to Bugsnag automatically.
But if you handle an exception in your code but still want see it in Bugsnag then you need to report it manually.
So in the same way, if you use data values for errors you could report those to Bugsnag manually.


NS
For the back half of this talk I want to get into some more Salsify-specific details.
At the beginning I was talking about doing the more deliberate design for error handling,
but the truth is we already do that to some degree in our shared libraries.

NS
Starting out on the backend, here's a snippet from the SalsifyGraphQLServer ruby gem
which I've shortened to show on the slide.
For every GraphQL request, the BaseController will catch exceptions as a last resort.
It uses our ExceptionReporter gem to report them to Bugsnag.
Then it translates the error into an API response following GraphQL conventions for an error payload.

(pause to look at code)

NS
For background jobs, Salsify has an extension to Delayed Job.
It has a similar approach of catching errors and reporting them to Bugsnag, and that happens at the top level where the job
is kicked off.
(pause to look at code)

So if you're using these libraries then you automatically have this error handling framework.
And this is a very helpful default, but by itself it's not enough to attain high quality error handling.

What I've shown so far is backend only. But once we translate the error into an API response payload, then what?
Or in the case of a background job, once we update a database row to record that this action failed, then what?

We still need to communicate to the end user.

Making that final step, connecting the dots on the client side, really improves quality a lot.
That may be an obvious point but in real world development it's easy for it to fall through the cracks.

NS
That said, just as with the backend libraries, we already do have some built-in default error handling within the main Salsify client app.

What the frontend error handler service provides is when an Ember route tries to load data from the API,
but the API request returns an error status like a 500,
the client will flash an error message in a bar near the top of the screen.
It's a bit generic but at least it's providing feedback to the end-user that something went wrong.

NS
But remember those examples I showed at the beginning
with the Enhanced Content where the API returned errors,
but the end user had no signal in the UI.

So, in theory Salsify has this built-in feedback in the UI for failed API requests,
but in practice it's not always working.

In those specific examples there are a couple different reasons why it didn't work
that come out of low-level details in the Enhanced Content engine.
So you could blame the EC engine for this.
But when we're working on an Ember engine like this,
in a normal development workflow we can't see that error message behavior for failed requests,
because it's provided by the main app in dandelion. The only way to see it is to package the engine into dandelion
and test end-to-end, including forcing the backend API server to return a 500.

Also with our current setup, we can't write an automated test
in the Enhanced Content engine that realistically exercises that error message bar for a failed API request,
again because in production it's partially provided by dandelion.

This is a place where the micro-frontends initiative should help, because a micro-app will
be able to manage more of its own UI, including its error display, so we won't have the same pitfalls as with an engine.

Still though, I'd say the current dandelion client has the right overall idea to have a default
behavior where if an API request fails, let's at least provide some visual feedback.

Because it ultimately doesn't matter whether the server indicates errors in a well-formatted way,
if we don't carry that through end-to-end so that the client communicates the problem to the user.

In these examples I focused on synchronous web requests,
but communication of background job failures might be even more important for a lot of Salsify features.

As I showed before we have the backend error reporting extension for DelayedJob,
but for actually communicating background job failures to end users,
that's an example where the status quo is to figure it out ad hoc.
Usually, each time we add a new background job, the approach for handling failures isn't covered.
Then over time we see failures in production and it's like OK now we need to devise some UX to handle this case.
And we're starting out with basic questions like, what screen do we even display the error on?

So one actionable takeaway here is every time we add a new background job, consider how to communicate when it fails, and then verify that it works.
Similarly, for any new API request the client makes, a good baseline is to verify that failures will flash an error message in the style of the main dandelion client.

NS
Beyond server errors, I want to cover errors in the client itself,
for example in the logic of an Ember component.

NS
In this slide, I have a catch block set up that handles when I call this undefined function named badFunc.

Build Out 1

But there's no catch block lower down when I call anotherBadFunc.

When a JS runtime error happens but it's not handled by any catch block,
the browser will fire the window.onerror event.

Build Out 2

That can be configured to run a function as a last resort error handler.


NS
For rejected promises, similar idea but slightly different.

Build Out
Here I have a promise that will reject because it tries to parse HTML as JSON.
But in this code there's no catch chained onto the promise.

NS
In this case the browser will fire the unhandledrejection event.

Like window.onerror, this can be configured as a last resort handler for rejected promises.

In fact, the basic way to configure Bugsnag on the browser side is to set up window.onerror and unhandledrejection
to report errors to Bugsnag.

NS
In our case though, Ember provides a function, Ember.onerror, that's meant as the backstop for unhandled errors in Ember apps.

Build Out
And then Salsify's error-reporting library abstracts over Ember.onerror.
Ultimately, the error-reporting library configures reporting to Bugsnag.
That happens once in Dandelion. That one-time setup then applies to our mounted engines.

But it does mean that in your engine you can't use these top-level error events yourself.
In particular you can't use them as a way to communicate problems to end users, in addition to Bugsnag.
This is another place where the micro-frontends project will enable improvements.

NS
Now let me make this more visual with an example of a client error.
Here we're looking at the list of Enhanced Content layouts again.

Notice the rows of the table. They're Ember components.

Build Out
So we have a component representing the table row.
And then we have a couple components nested inside of it

Build Out
one that displays what retailers you've published this layout to,
Build Out
and another component that shows the status of the layout.

So imagine that that "Most Recent Status" component throws an exception, what's going to happen?

NS
Well the overall layout table still renders, but because the status component errored, everything
after it is gone. You can see there's no status, but also the rows after the first one aren't showing.

Build Out
Also, unexpectedly the error thrown by that component
also causes this Amazon quota bar up at the top to break as well, where now it's not showing counts anymore.
That's a somewhat arbitrary side effect of the fact that that the Amazon count is asynchronously fetched,
and the component error prevented it from processing.

So bottom line, for end-users again the behavior when errors happen is puzzling.
The page definitely looks off, but there's no direct message that an error occurred.

More than anything else, we want errors like this reported to Bugsnag so we
can address it and prevent it from happening in the future. But is there anything more to do to create a higher quality experience?

The first approach that came to my mind was to flash an error message on the same page.
But as you can see in this example, the effects of a component error on the page rendering can be unpredictable,
so there's no guarantee that an in-page error display would always work.

A more heavy-handed but robust approach would be to handle client-side errors
like this by fully redirecting to an error page.
Make it more like a server-rendered website that responds with an error page.
It's a little severe, but again for an unexpected error our strategy devolves to communication,
so being loud and clear seems OK.

NS

I want to go back to the server-side for a moment and discuss
the tactic that our DelayedJob extension takes, where it handles errors at the edges.
It's at the entrypoint to the program, at the top-level of executing a given background job.
That's a starting point for some business domain action. That makes it a good seam for communicating errors.

If the backend handles all errors at the boundary of the action,
it provides a natural subject to communicate about to the end user.
If it failed, then no matter why it failed,
whatever deep internal code of the application where the problem occurred,
as a default communication strategy we can just say reference the top-level domain action that prompted the error.

Like if we're executing a background job that publishes Enhanced Content, then at the entry point to that job
we know that context, so the simple strategy is to handle all errors there and for the end-user, just say
"This attempt to publish your content failed."

That strategy also works nicely for REST APIs because each URL is an entry point for a domain action.
So the web controller can simply say something like "Failed to copy your Enhanced Content layout," regardless of the lower-level
details that caused the error.

NS
But notice it doesn't quite work that neatly for GraphQL because we don't have server-defined
seams like that, since the GraphQL endpoint is processing arbitrary queries.

Build Out 1
In this example query,
suppose one of the GraphQL field resolvers raises an exception.

Build Out 2
Thanks to SalsifyGraphQLServer's BaseController, we'll package this into a GraphQL errors response.
It will set the returned message to "Internal server error".
If we display that message in the client it won't
communicate anything about specific action that prompted the error.
That's extra relevant for SPAs because the client
is often firing off multiple requests,
they're not one-to-one with the user's clicks.

NS
So one way to try to confront that is to view each GraphQL field as an entry point.

Build Out 1
In this version I'm rescuing errors for the field-level resolver and turning it into a user-oriented error message.

Build Out 2
And then the response provides a message that the client could display.
But you can see that adding error handlers at this level would add a ton of extra code.
Plus, the error message we could set for an individual field still
couldn't know how to communicate about the overall request.

So for GraphQL requests I'd want re-frame the understanding of what the entrypoint is, and say it's actually
the client side request. The client will have context on the domain action it's doing when it submits that
GraphQL query, so if the server errors, the client can display a message referencing that domain action.
And then if the client wants to add in the message field returned by the server,
sure, sometimes that may add some helpful details.
But the key point is we've defined the entry point in a way that supports a reasonable communication to the end user.

OK. So then for errors in the client application itself we have a similar challenge
because the client has so many entry points.
Every component action and every attribute in every nested component and
are independent entry points that can error.

For component actions, those are mostly one-to-one with end-user actions.
Therefore they make good entrypoints to communicate about,
so it would make sense to catch exceptions at their top-level.

For component attributes, catching exceptions at all of them individually
would add a lot of code and would not be the right level of detail to communicate.

And again I'd suggest re-defining the entrypoint,
and zooming out to those built-in browser events for unhandled errors.
That creates a backstop to ensure we have communication in place for any error.

NS
Because the fundamental idea here is that when a runtime exception happens,
to achieve a good quality user experience we need to communicate it,
but moreover, communicating it is usually the only reliable thing we can do.

I see this as a key insight, because historically most programming languages signal errors in a way
that blurs together different kinds of issues, so it's too easy to lose track of the point
that either the program knows in advance how to deal with this issue as part of the its domain,
or it doesn't, so its only recourse is to report the issue to humans.

That drives this design of pushing error handling to the boundaries.
Because if we understand exceptions this way, then there's absolutely no point messing around
with error handling at all in lower-levels of our programs.

This approach is different than a lot of real-word code, including what I've written myself,
where error handling logic is strewn throughout the codebase.
You'll see some try-catches on some functions but not all,
some modules have defined a custom Exception class, others just throw built-in Exceptions,
sometimes a function will just return null or some other error data that it expects the caller to check.

But none of these techniques provide much value for creating a good overall user experience.

The solution is to make sure we deal with exceptions adequately at the boundaries.
Because then we can have the confidence to not bother with error handling code at lower levels at all.
Literally, be optimistic, only write code that assumes everything is going to work. It simplifies the codebase.
And when an exception is thrown just handle it at the boundary
by telling the user that it happened, and report it to Bugsnag.

Now once in awhile we will be calling a function and we know it can throw an exception
but our program has a clear way to recover and keep going.
So in that case I'd say sure, it make sense to wrap a handler around that one call.
Situations like that are pretty rare though, and it's fine to let them emerge in production use.

This handle-at-the-boundary approach is a good mental framework,
because it naturally implies a checklist, where each time we add a business feature,
that's the time to ask, what is the entry point here,
and when it errors how will we communicate to end-users?
Pull that off and you have high quality error handling.

OK that's it, thank you, and I'm happy to take any questions or comments.

